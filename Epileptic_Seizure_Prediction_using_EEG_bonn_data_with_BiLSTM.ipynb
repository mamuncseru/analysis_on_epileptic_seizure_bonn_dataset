{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgmUymaifAdSz9bQAUXaK8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamuncseru/analysis_on_epileptic_seizure_bonn_dataset/blob/main/Epileptic_Seizure_Prediction_using_EEG_bonn_data_with_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "xTXKW2AFGWS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as Data\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "import keras\n",
        "from keras.layers import Dense, Convolution1D, MaxPool1D, Flatten, Dropout\n",
        "from keras.layers import Input, LSTM\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "# from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "Fddr3ZGBGjiq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Data"
      ],
      "metadata": {
        "id": "InzZU6XeIPbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv('https://raw.githubusercontent.com/mamuncseru/analysis_on_epileptic_seizure_bonn_dataset/main/Epileptic%20Seizure%20Recognition.csv')\n",
        "raw_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ZGEu4727IgO6",
        "outputId": "da86da63-4999-474d-dc3b-bda0ba69ab6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n",
              "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n",
              "1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n",
              "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n",
              "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n",
              "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n",
              "\n",
              "   X172  X173  X174  X175  X176  X177  X178  y  \n",
              "0   -31   -77  -103  -127  -116   -83   -51  4  \n",
              "1   146   152   157   156   154   143   129  1  \n",
              "2    48    19   -12   -30   -35   -35   -36  5  \n",
              "3   -80   -77   -85   -77   -72   -69   -65  5  \n",
              "4   -12   -32   -41   -65   -83   -89   -73  5  \n",
              "\n",
              "[5 rows x 180 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49762b46-40b7-4baf-b83d-f90916078aed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>...</th>\n",
              "      <th>X170</th>\n",
              "      <th>X171</th>\n",
              "      <th>X172</th>\n",
              "      <th>X173</th>\n",
              "      <th>X174</th>\n",
              "      <th>X175</th>\n",
              "      <th>X176</th>\n",
              "      <th>X177</th>\n",
              "      <th>X178</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>X21.V1.791</td>\n",
              "      <td>135</td>\n",
              "      <td>190</td>\n",
              "      <td>229</td>\n",
              "      <td>223</td>\n",
              "      <td>192</td>\n",
              "      <td>125</td>\n",
              "      <td>55</td>\n",
              "      <td>-9</td>\n",
              "      <td>-33</td>\n",
              "      <td>...</td>\n",
              "      <td>-17</td>\n",
              "      <td>-15</td>\n",
              "      <td>-31</td>\n",
              "      <td>-77</td>\n",
              "      <td>-103</td>\n",
              "      <td>-127</td>\n",
              "      <td>-116</td>\n",
              "      <td>-83</td>\n",
              "      <td>-51</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>X15.V1.924</td>\n",
              "      <td>386</td>\n",
              "      <td>382</td>\n",
              "      <td>356</td>\n",
              "      <td>331</td>\n",
              "      <td>320</td>\n",
              "      <td>315</td>\n",
              "      <td>307</td>\n",
              "      <td>272</td>\n",
              "      <td>244</td>\n",
              "      <td>...</td>\n",
              "      <td>164</td>\n",
              "      <td>150</td>\n",
              "      <td>146</td>\n",
              "      <td>152</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>143</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>X8.V1.1</td>\n",
              "      <td>-32</td>\n",
              "      <td>-39</td>\n",
              "      <td>-47</td>\n",
              "      <td>-37</td>\n",
              "      <td>-32</td>\n",
              "      <td>-36</td>\n",
              "      <td>-57</td>\n",
              "      <td>-73</td>\n",
              "      <td>-85</td>\n",
              "      <td>...</td>\n",
              "      <td>57</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>19</td>\n",
              "      <td>-12</td>\n",
              "      <td>-30</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-36</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>X16.V1.60</td>\n",
              "      <td>-105</td>\n",
              "      <td>-101</td>\n",
              "      <td>-96</td>\n",
              "      <td>-92</td>\n",
              "      <td>-89</td>\n",
              "      <td>-95</td>\n",
              "      <td>-102</td>\n",
              "      <td>-100</td>\n",
              "      <td>-87</td>\n",
              "      <td>...</td>\n",
              "      <td>-82</td>\n",
              "      <td>-81</td>\n",
              "      <td>-80</td>\n",
              "      <td>-77</td>\n",
              "      <td>-85</td>\n",
              "      <td>-77</td>\n",
              "      <td>-72</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>X20.V1.54</td>\n",
              "      <td>-9</td>\n",
              "      <td>-65</td>\n",
              "      <td>-98</td>\n",
              "      <td>-102</td>\n",
              "      <td>-78</td>\n",
              "      <td>-48</td>\n",
              "      <td>-16</td>\n",
              "      <td>0</td>\n",
              "      <td>-21</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>-12</td>\n",
              "      <td>-32</td>\n",
              "      <td>-41</td>\n",
              "      <td>-65</td>\n",
              "      <td>-83</td>\n",
              "      <td>-89</td>\n",
              "      <td>-73</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 180 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49762b46-40b7-4baf-b83d-f90916078aed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49762b46-40b7-4baf-b83d-f90916078aed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49762b46-40b7-4baf-b83d-f90916078aed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypk0ZnqJInSM",
        "outputId": "fd33c4c2-24fc-4699-d8da-d8e726304760"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11500, 180)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "DDLWuHqNIro9",
        "outputId": "9e60a34d-d535-49e1-cb26-b7d8690f97d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Unnamed   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  \\\n",
              "0      X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   \n",
              "1      X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   \n",
              "2         X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57   \n",
              "3       X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   \n",
              "4       X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4   \n",
              "...           ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
              "11495  X22.V1.114  -22  -22  -23  -26  -36  -42  -45  -42  -45  ...    15   \n",
              "11496  X19.V1.354  -47  -11   28   77  141  211  246  240  193  ...   -65   \n",
              "11497    X8.V1.28   14    6  -13  -16   10   26   27   -9    4  ...   -65   \n",
              "11498  X10.V1.932  -40  -25   -9  -12   -2   12    7   19   22  ...   121   \n",
              "11499  X16.V1.210   29   41   57   72   74   62   54   43   31  ...   -59   \n",
              "\n",
              "       X171  X172  X173  X174  X175  X176  X177  X178  y  \n",
              "0       -15   -31   -77  -103  -127  -116   -83   -51  4  \n",
              "1       150   146   152   157   156   154   143   129  1  \n",
              "2        64    48    19   -12   -30   -35   -35   -36  5  \n",
              "3       -81   -80   -77   -85   -77   -72   -69   -65  5  \n",
              "4         2   -12   -32   -41   -65   -83   -89   -73  5  \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ... ..  \n",
              "11495    16    12     5    -1   -18   -37   -47   -48  2  \n",
              "11496   -33    -7    14    27    48    77   117   170  1  \n",
              "11497   -48   -61   -62   -67   -30    -2    -1    -8  5  \n",
              "11498   135   148   143   116    86    68    59    55  3  \n",
              "11499   -25    -4     2     5     4    -2     2    20  4  \n",
              "\n",
              "[11500 rows x 180 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a922a72e-6dd0-4063-86f3-cb944c2ea738\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>...</th>\n",
              "      <th>X170</th>\n",
              "      <th>X171</th>\n",
              "      <th>X172</th>\n",
              "      <th>X173</th>\n",
              "      <th>X174</th>\n",
              "      <th>X175</th>\n",
              "      <th>X176</th>\n",
              "      <th>X177</th>\n",
              "      <th>X178</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>X21.V1.791</td>\n",
              "      <td>135</td>\n",
              "      <td>190</td>\n",
              "      <td>229</td>\n",
              "      <td>223</td>\n",
              "      <td>192</td>\n",
              "      <td>125</td>\n",
              "      <td>55</td>\n",
              "      <td>-9</td>\n",
              "      <td>-33</td>\n",
              "      <td>...</td>\n",
              "      <td>-17</td>\n",
              "      <td>-15</td>\n",
              "      <td>-31</td>\n",
              "      <td>-77</td>\n",
              "      <td>-103</td>\n",
              "      <td>-127</td>\n",
              "      <td>-116</td>\n",
              "      <td>-83</td>\n",
              "      <td>-51</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>X15.V1.924</td>\n",
              "      <td>386</td>\n",
              "      <td>382</td>\n",
              "      <td>356</td>\n",
              "      <td>331</td>\n",
              "      <td>320</td>\n",
              "      <td>315</td>\n",
              "      <td>307</td>\n",
              "      <td>272</td>\n",
              "      <td>244</td>\n",
              "      <td>...</td>\n",
              "      <td>164</td>\n",
              "      <td>150</td>\n",
              "      <td>146</td>\n",
              "      <td>152</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>143</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>X8.V1.1</td>\n",
              "      <td>-32</td>\n",
              "      <td>-39</td>\n",
              "      <td>-47</td>\n",
              "      <td>-37</td>\n",
              "      <td>-32</td>\n",
              "      <td>-36</td>\n",
              "      <td>-57</td>\n",
              "      <td>-73</td>\n",
              "      <td>-85</td>\n",
              "      <td>...</td>\n",
              "      <td>57</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>19</td>\n",
              "      <td>-12</td>\n",
              "      <td>-30</td>\n",
              "      <td>-35</td>\n",
              "      <td>-35</td>\n",
              "      <td>-36</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>X16.V1.60</td>\n",
              "      <td>-105</td>\n",
              "      <td>-101</td>\n",
              "      <td>-96</td>\n",
              "      <td>-92</td>\n",
              "      <td>-89</td>\n",
              "      <td>-95</td>\n",
              "      <td>-102</td>\n",
              "      <td>-100</td>\n",
              "      <td>-87</td>\n",
              "      <td>...</td>\n",
              "      <td>-82</td>\n",
              "      <td>-81</td>\n",
              "      <td>-80</td>\n",
              "      <td>-77</td>\n",
              "      <td>-85</td>\n",
              "      <td>-77</td>\n",
              "      <td>-72</td>\n",
              "      <td>-69</td>\n",
              "      <td>-65</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>X20.V1.54</td>\n",
              "      <td>-9</td>\n",
              "      <td>-65</td>\n",
              "      <td>-98</td>\n",
              "      <td>-102</td>\n",
              "      <td>-78</td>\n",
              "      <td>-48</td>\n",
              "      <td>-16</td>\n",
              "      <td>0</td>\n",
              "      <td>-21</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>-12</td>\n",
              "      <td>-32</td>\n",
              "      <td>-41</td>\n",
              "      <td>-65</td>\n",
              "      <td>-83</td>\n",
              "      <td>-89</td>\n",
              "      <td>-73</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11495</th>\n",
              "      <td>X22.V1.114</td>\n",
              "      <td>-22</td>\n",
              "      <td>-22</td>\n",
              "      <td>-23</td>\n",
              "      <td>-26</td>\n",
              "      <td>-36</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>-42</td>\n",
              "      <td>-45</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>-18</td>\n",
              "      <td>-37</td>\n",
              "      <td>-47</td>\n",
              "      <td>-48</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11496</th>\n",
              "      <td>X19.V1.354</td>\n",
              "      <td>-47</td>\n",
              "      <td>-11</td>\n",
              "      <td>28</td>\n",
              "      <td>77</td>\n",
              "      <td>141</td>\n",
              "      <td>211</td>\n",
              "      <td>246</td>\n",
              "      <td>240</td>\n",
              "      <td>193</td>\n",
              "      <td>...</td>\n",
              "      <td>-65</td>\n",
              "      <td>-33</td>\n",
              "      <td>-7</td>\n",
              "      <td>14</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>77</td>\n",
              "      <td>117</td>\n",
              "      <td>170</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11497</th>\n",
              "      <td>X8.V1.28</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>-13</td>\n",
              "      <td>-16</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>-9</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>-65</td>\n",
              "      <td>-48</td>\n",
              "      <td>-61</td>\n",
              "      <td>-62</td>\n",
              "      <td>-67</td>\n",
              "      <td>-30</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11498</th>\n",
              "      <td>X10.V1.932</td>\n",
              "      <td>-40</td>\n",
              "      <td>-25</td>\n",
              "      <td>-9</td>\n",
              "      <td>-12</td>\n",
              "      <td>-2</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>...</td>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>148</td>\n",
              "      <td>143</td>\n",
              "      <td>116</td>\n",
              "      <td>86</td>\n",
              "      <td>68</td>\n",
              "      <td>59</td>\n",
              "      <td>55</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11499</th>\n",
              "      <td>X16.V1.210</td>\n",
              "      <td>29</td>\n",
              "      <td>41</td>\n",
              "      <td>57</td>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "      <td>62</td>\n",
              "      <td>54</td>\n",
              "      <td>43</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>-59</td>\n",
              "      <td>-25</td>\n",
              "      <td>-4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>-2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11500 rows × 180 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a922a72e-6dd0-4063-86f3-cb944c2ea738')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a922a72e-6dd0-4063-86f3-cb944c2ea738 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a922a72e-6dd0-4063-86f3-cb944c2ea738');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = raw_data.values\n",
        "data = data[0:11501, 1:180]\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJXy0YBsIz2U",
        "outputId": "96957088-b3eb-4acb-97fa-75dedf972afb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11500, 179)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBTYfRlFJAja",
        "outputId": "7272e94e-a25d-4851-eaa3-35f24bfc9136"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifying data categories"
      ],
      "metadata": {
        "id": "IBm8psg-JB5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D = data\n",
        "df_1 = D[D[:, 178] == 1]\n",
        "df_2 = D[D[:, 178] == 2]\n",
        "df_3 = D[D[:, 178] == 3]\n",
        "df_4 = D[D[:, 178] == 4]\n",
        "df_5 = D[D[:, 178] == 5]\n",
        "\n",
        "print(df_1.shape)\n",
        "print(df_2.shape)\n",
        "print(df_3.shape)\n",
        "print(df_4.shape)\n",
        "print(df_5.shape)\n",
        "\n",
        "df_1 = df_1.astype(int)\n",
        "df_2 = df_2.astype(int)\n",
        "df_3 = df_3.astype(int)\n",
        "df_4 = df_4.astype(int)\n",
        "df_5 = df_5.astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEHky3lXJG9J",
        "outputId": "dfb5cba2-6f25-4b8f-8c69-ffcc1f7d1ef6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2300, 179)\n",
            "(2300, 179)\n",
            "(2300, 179)\n",
            "(2300, 179)\n",
            "(2300, 179)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 1: Comparing CNN and BiLSTM on Epilepsy versus Healthy Data Categories"
      ],
      "metadata": {
        "id": "haXIsac3JtuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_3[:, 178] = df_3[:, 178] - 3\n",
        "D1 = np.concatenate([df_1, df_3])"
      ],
      "metadata": {
        "id": "uFzung9oK2B_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srCAEY1PM8Ux",
        "outputId": "6f741aeb-73f1-415e-cb1d-2067c421a913"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4600, 179)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating training (80), validation(10) and test(10) data from category 1 and 3\n"
      ],
      "metadata": {
        "id": "qzmNVKQMMqOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_rows = D1.shape[0]\n",
        "\n",
        "random_indices = np.random.choice(number_of_rows, size=int(number_of_rows*0.8), replace=False)\n",
        "\n",
        "label_train = D1[random_indices, -1]\n",
        "data_train = D1[random_indices, :-1]\n",
        "\n",
        "D1_rest = np.delete(D1, random_indices, 0)\n",
        "\n",
        "number_of_rows = D1_rest.shape[0]\n",
        "random_indices = np.random.choice(number_of_rows, size=int(number_of_rows*0.5), replace=False)\n",
        "\n",
        "label_val = D1_rest[random_indices, -1]\n",
        "data_val = D1_rest[random_indices, :-1]\n",
        "\n",
        "D1_rest_rest = np.delete(D1_rest, random_indices, 0)\n",
        "\n",
        "label_test = D1_rest_rest[:, -1]\n",
        "data_test = D1_rest_rest[:, :-1]\n",
        "\n",
        "data_train = np.expand_dims(data_train, axis=2)\n",
        "data_val = np.expand_dims(data_val, axis=2)\n",
        "data_test = np.expand_dims(data_test, axis=2)\n",
        "\n",
        "print(label_train.shape, data_train.shape)\n",
        "print(label_val.shape, data_val.shape)\n",
        "print(label_test.shape, data_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko_q7hjdLDYM",
        "outputId": "d870a6db-cc78-446f-c4d1-ecd2bfddf338"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3680,) (3680, 178, 1)\n",
            "(460,) (460, 178, 1)\n",
            "(460,) (460, 178, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define model evaluation function"
      ],
      "metadata": {
        "id": "gLqFn0g7NCag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(history, X_test, y_test, model):\n",
        "  scores = model.evaluate((X_test), y_test, verbose=0)\n",
        "  print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "  print(history)\n",
        "  fig1, ax_acc = plt.subplots()\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title('Model - Accuracy')\n",
        "  plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "  plt.show()\n",
        "\n",
        "  fig2, ax_loss = plt.subplots()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title('Model - Loss')\n",
        "  plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.show()\n",
        "  target_names = ['1', '2', '3']\n",
        "\n",
        "  y_true = []\n",
        "  for element in y_test:\n",
        "    y_true.append(np.argmax(element))\n",
        "\n",
        "  prediction_proba = model.predict(X_test)\n",
        "  prediction = np.argmax(prediction_proba, axis=1)\n",
        "  cnf_matrix = confusion_matrix(y_true, prediction)"
      ],
      "metadata": {
        "id": "fRW74qx7MtiO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define CNN network"
      ],
      "metadata": {
        "id": "2wmS689dOoBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def network_CNN(X_train, y_train):\n",
        "  im_shape = (X_train.shape[1], 1)\n",
        "  inputs_cnn = Input(shape=(im_shape), name='inputs_cnn')\n",
        "\n",
        "  conv1d_1 = layers.Conv1D(filters=32, kernel_size=6)(inputs_cnn)\n",
        "  batch_normalization = BatchNormalization()(conv1d_1)\n",
        "  max_pooling1d = layers.MaxPooling1D(2, padding='same')(batch_normalization)\n",
        "\n",
        "  conv1d_2 = layers.Conv1D(filters=64, kernel_size=3)(max_pooling1d)\n",
        "  batch_normalization_1 = BatchNormalization()(conv1d_2)\n",
        "  max_pooling1d_1 = layers.MaxPooling1D(2, padding='same')(batch_normalization_1)\n",
        "\n",
        "  flatten = Flatten()(max_pooling1d_1)\n",
        "\n",
        "  dense = Dense(32)(flatten)\n",
        "  dense_1 = Dense(16)(dense)\n",
        "\n",
        "  main_output = Dense(2)(dense_1)\n",
        "\n",
        "  model1 = Model(inputs = inputs_cnn, outputs=main_output)\n",
        "  model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model1\n"
      ],
      "metadata": {
        "id": "AIzooKcwOuvB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define CNN model to be trained on epileptic vs healthy data\n",
        "model1 = network_CNN(data_train, label_train)\n",
        "print(model1.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QanyhwcAQQ9Y",
        "outputId": "55bbbf05-a3e7-403f-efd7-3f0d2cf81962"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs_cnn (InputLayer)     [(None, 178, 1)]          0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 173, 32)           224       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 173, 32)          128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 87, 32)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 85, 64)            6208      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 85, 64)           256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 43, 64)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2752)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                88096     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 95,474\n",
            "Trainable params: 95,282\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy.sql.expression import true\n",
        "## Train CNN network on epileptic vs healthy data\n",
        "# Save model at highest validation accuracy\n",
        "save_path = 'checkpoint_1'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath = save_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "history = model1.fit(data_train, label_train, epochs=500, batch_size=32, validation_data=(data_val, label_val), callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvpBnmIWQgEb",
        "outputId": "be640b61-a7d0-4b71-ae41-24194ceccd14"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "115/115 [==============================] - 7s 31ms/step - loss: 0.8628 - accuracy: 0.8576 - val_loss: 1.0866 - val_accuracy: 0.6435\n",
            "Epoch 2/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6738 - accuracy: 0.7345 - val_loss: 0.6042 - val_accuracy: 0.7152\n",
            "Epoch 3/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6736 - accuracy: 0.7853 - val_loss: 0.6434 - val_accuracy: 0.8065\n",
            "Epoch 4/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6496 - accuracy: 0.8168 - val_loss: 0.6449 - val_accuracy: 0.8109\n",
            "Epoch 5/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6609 - accuracy: 0.7783 - val_loss: 0.6540 - val_accuracy: 0.7457\n",
            "Epoch 6/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6669 - accuracy: 0.7717 - val_loss: 0.6881 - val_accuracy: 0.8348\n",
            "Epoch 7/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.7112 - accuracy: 0.8231 - val_loss: 0.6901 - val_accuracy: 0.8435\n",
            "Epoch 8/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.7007 - accuracy: 0.8489 - val_loss: 0.6916 - val_accuracy: 0.8500\n",
            "Epoch 9/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6930 - accuracy: 0.8465 - val_loss: 0.6931 - val_accuracy: 0.8457\n",
            "Epoch 10/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.8457 - val_loss: 0.6931 - val_accuracy: 0.8500\n",
            "Epoch 11/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.8397 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 12/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.8421 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 13/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.8424 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 14/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.8500 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 15/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.6931 - accuracy: 0.8440 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 16/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.8451 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 17/500\n",
            "115/115 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.8438 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 18/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6930 - accuracy: 0.8440 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 19/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.8457 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 20/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.8402 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 21/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.6931 - accuracy: 0.8361 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 22/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.6931 - accuracy: 0.8470 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 23/500\n",
            "115/115 [==============================] - 4s 32ms/step - loss: 0.6931 - accuracy: 0.8476 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 24/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.8448 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 25/500\n",
            "115/115 [==============================] - 4s 32ms/step - loss: 0.6930 - accuracy: 0.8465 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 26/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6930 - accuracy: 0.8454 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 27/500\n",
            "115/115 [==============================] - 4s 35ms/step - loss: 0.6930 - accuracy: 0.8443 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 28/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.8519 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 29/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6930 - accuracy: 0.8459 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 30/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6931 - accuracy: 0.8421 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 31/500\n",
            "115/115 [==============================] - 5s 45ms/step - loss: 0.6930 - accuracy: 0.8435 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 32/500\n",
            "115/115 [==============================] - 4s 35ms/step - loss: 0.6931 - accuracy: 0.8486 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 33/500\n",
            "115/115 [==============================] - 4s 34ms/step - loss: 0.6930 - accuracy: 0.8424 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 34/500\n",
            "115/115 [==============================] - 5s 42ms/step - loss: 0.6930 - accuracy: 0.8462 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 35/500\n",
            "115/115 [==============================] - 4s 36ms/step - loss: 0.6931 - accuracy: 0.8421 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 36/500\n",
            "115/115 [==============================] - 5s 39ms/step - loss: 0.6930 - accuracy: 0.8489 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 37/500\n",
            "115/115 [==============================] - 4s 39ms/step - loss: 0.6930 - accuracy: 0.8454 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 38/500\n",
            "115/115 [==============================] - 3s 30ms/step - loss: 0.6931 - accuracy: 0.8489 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 39/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6930 - accuracy: 0.8432 - val_loss: 0.6931 - val_accuracy: 0.8478\n",
            "Epoch 40/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.7105 - accuracy: 0.7685 - val_loss: 0.6837 - val_accuracy: 0.5348\n",
            "Epoch 41/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.7140 - accuracy: 0.5198 - val_loss: 0.6866 - val_accuracy: 0.4804\n",
            "Epoch 42/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6993 - accuracy: 0.5076 - val_loss: 0.6871 - val_accuracy: 0.4761\n",
            "Epoch 43/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6916 - accuracy: 0.5049 - val_loss: 0.6901 - val_accuracy: 0.4761\n",
            "Epoch 44/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6913 - accuracy: 0.5054 - val_loss: 0.6901 - val_accuracy: 0.4761\n",
            "Epoch 45/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6919 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 46/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 47/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 48/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 49/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 50/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 51/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 52/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 53/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 54/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 55/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 56/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 57/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 58/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 59/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 60/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 61/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 62/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 63/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 64/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 65/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 66/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 67/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 68/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 69/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 70/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 71/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 72/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 73/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 74/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 75/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 76/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 77/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 78/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 79/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 80/500\n",
            "115/115 [==============================] - 3s 30ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 81/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 82/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 83/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 84/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 85/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 86/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 87/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 88/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 89/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 90/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 91/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 92/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 93/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 94/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 95/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 96/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 97/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 98/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 99/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 100/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 101/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 102/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 103/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 104/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 105/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 106/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 107/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 108/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 109/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 110/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 111/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 112/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 113/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 114/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 115/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 116/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 117/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 118/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 119/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 120/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 121/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 122/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 123/500\n",
            "115/115 [==============================] - 2s 17ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 124/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 125/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 126/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 127/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6924 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 128/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 129/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 130/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 131/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 132/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 133/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 134/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 135/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 136/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 137/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 138/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 139/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 140/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 141/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6922 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 142/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 143/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 144/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 145/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 146/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 147/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 148/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 149/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 150/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6922 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 151/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 152/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 153/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 154/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 155/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 156/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 157/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 158/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 159/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 160/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 161/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 162/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 163/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 164/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 165/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 166/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 167/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 168/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 169/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 170/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 171/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 172/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 173/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 174/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 175/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 176/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 177/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 178/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 179/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 180/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 181/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 182/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 183/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 184/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 185/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 186/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 187/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 188/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 189/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 190/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 191/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 192/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 193/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 194/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 195/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 196/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 197/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 198/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 199/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6924 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 200/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 201/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 202/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 203/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 204/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6922 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 205/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 206/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 207/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 208/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6922 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 209/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 210/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6922 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 211/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 212/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6926 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 213/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 214/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 215/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 216/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 217/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6922 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 218/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 219/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 220/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6922 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 221/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 222/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6924 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 223/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 224/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5057 - val_loss: 0.6931 - val_accuracy: 0.4761\n",
            "Epoch 225/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6899 - accuracy: 0.5057 - val_loss: 0.6796 - val_accuracy: 0.4761\n",
            "Epoch 226/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.5149 - val_loss: 0.6916 - val_accuracy: 0.4935\n",
            "Epoch 227/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6923 - accuracy: 0.5264 - val_loss: 0.6916 - val_accuracy: 0.4891\n",
            "Epoch 228/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6888 - accuracy: 0.5245 - val_loss: 0.6916 - val_accuracy: 0.4935\n",
            "Epoch 229/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.7006 - accuracy: 0.5307 - val_loss: 0.6916 - val_accuracy: 0.4739\n",
            "Epoch 230/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.7008 - accuracy: 0.5049 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 231/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.7093 - accuracy: 0.5043 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 232/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6968 - accuracy: 0.5049 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 233/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.7012 - accuracy: 0.5046 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 234/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6968 - accuracy: 0.5038 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 235/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6970 - accuracy: 0.5041 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 236/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6968 - accuracy: 0.5046 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 237/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6928 - accuracy: 0.5043 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 238/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.7012 - accuracy: 0.5046 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 239/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.7012 - accuracy: 0.5041 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 240/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.7052 - accuracy: 0.5035 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 241/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6966 - accuracy: 0.5046 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 242/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6928 - accuracy: 0.5043 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 243/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.7008 - accuracy: 0.5043 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 244/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.7053 - accuracy: 0.5038 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 245/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.7010 - accuracy: 0.5049 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 246/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6970 - accuracy: 0.5041 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 247/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.7012 - accuracy: 0.5043 - val_loss: 0.6916 - val_accuracy: 0.4761\n",
            "Epoch 248/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6927 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.4717\n",
            "Epoch 249/500\n",
            "115/115 [==============================] - 2s 22ms/step - loss: 0.6928 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.4739\n",
            "Epoch 250/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6930 - accuracy: 0.5052 - val_loss: 0.6931 - val_accuracy: 0.4739\n",
            "Epoch 251/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6928 - accuracy: 0.5052 - val_loss: 0.6931 - val_accuracy: 0.4739\n",
            "Epoch 252/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6924 - accuracy: 0.5052 - val_loss: 0.6931 - val_accuracy: 0.4739\n",
            "Epoch 253/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6973 - accuracy: 0.4437 - val_loss: 0.6931 - val_accuracy: 0.3370\n",
            "Epoch 254/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3261\n",
            "Epoch 255/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.3845 - val_loss: 0.6931 - val_accuracy: 0.3304\n",
            "Epoch 256/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3856 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 257/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 258/500\n",
            "115/115 [==============================] - 2s 18ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 259/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3886 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 260/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 261/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.3818 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 262/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3872 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 263/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3845 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 264/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 265/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 266/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 267/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 268/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 269/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3883 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 270/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3880 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 271/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.3821 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 272/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 273/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 274/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3829 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 275/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3886 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 276/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3880 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 277/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 278/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3902 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 279/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 280/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3856 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 281/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 282/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.3872 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 283/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 284/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3878 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 285/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3878 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 286/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3818 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 287/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3812 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 288/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 289/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 290/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3878 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 291/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3840 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 292/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 293/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 294/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 295/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 296/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 297/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 298/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 299/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3832 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 300/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3840 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 301/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3927 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 302/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3826 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 303/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3851 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 304/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 305/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 306/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 307/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3853 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 308/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3821 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 309/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 310/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3815 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 311/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 312/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3837 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 313/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3891 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 314/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3891 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 315/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.3899 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 316/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.3829 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 317/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3823 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 318/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 319/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 320/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3826 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 321/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3851 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 322/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 323/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3832 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 324/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3913 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 325/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3924 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 326/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.3916 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 327/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6931 - accuracy: 0.3856 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 328/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 329/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3856 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 330/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 331/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3897 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 332/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3834 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 333/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 334/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3886 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 335/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 336/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3815 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 337/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 338/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 339/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 340/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3851 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 341/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3905 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 342/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6931 - accuracy: 0.3840 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 343/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 344/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3837 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 345/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 346/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3880 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 347/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3853 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 348/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.3812 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 349/500\n",
            "115/115 [==============================] - 2s 22ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 350/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3851 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 351/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 352/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3856 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 353/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.3837 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 354/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.3821 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 355/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3880 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 356/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3872 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 357/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 358/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3834 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 359/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3886 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 360/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3810 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 361/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3840 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 362/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 363/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3880 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 364/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.3910 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 365/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 366/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 367/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3894 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 368/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3829 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 369/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3891 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 370/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 371/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3823 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 372/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3821 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 373/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3872 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 374/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 375/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 376/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.3853 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 377/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 378/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 379/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3823 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 380/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3832 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 381/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.3872 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 382/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6931 - accuracy: 0.3853 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 383/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 384/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3832 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 385/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 386/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 387/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.3845 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 388/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3823 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 389/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 390/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3845 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 391/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3902 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 392/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 393/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3853 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 394/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3878 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 395/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 396/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 397/500\n",
            "115/115 [==============================] - 3s 23ms/step - loss: 0.6931 - accuracy: 0.3845 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 398/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 399/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3889 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 400/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3853 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 401/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3840 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 402/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 403/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 404/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 405/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3880 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 406/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 407/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3886 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 408/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 409/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6931 - accuracy: 0.3880 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 410/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3891 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 411/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 412/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3840 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 413/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 414/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.3891 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 415/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3837 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 416/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3886 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 417/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 418/500\n",
            "115/115 [==============================] - 2s 19ms/step - loss: 0.6931 - accuracy: 0.3910 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 419/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.3853 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 420/500\n",
            "115/115 [==============================] - 3s 22ms/step - loss: 0.6931 - accuracy: 0.3880 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 421/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 422/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.3856 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 423/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.3829 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 424/500\n",
            "115/115 [==============================] - 5s 39ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 425/500\n",
            "115/115 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.3791 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 426/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 427/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3886 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 428/500\n",
            "115/115 [==============================] - 4s 35ms/step - loss: 0.6931 - accuracy: 0.3902 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 429/500\n",
            "115/115 [==============================] - 4s 34ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 430/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.3883 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 431/500\n",
            "115/115 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 432/500\n",
            "115/115 [==============================] - 4s 34ms/step - loss: 0.6931 - accuracy: 0.3840 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 433/500\n",
            "115/115 [==============================] - 3s 30ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 434/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.3837 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 435/500\n",
            "115/115 [==============================] - 5s 39ms/step - loss: 0.6931 - accuracy: 0.3845 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 436/500\n",
            "115/115 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 437/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 438/500\n",
            "115/115 [==============================] - 4s 32ms/step - loss: 0.6931 - accuracy: 0.3837 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 439/500\n",
            "115/115 [==============================] - 5s 42ms/step - loss: 0.6931 - accuracy: 0.3837 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 440/500\n",
            "115/115 [==============================] - 3s 30ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 441/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 442/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 443/500\n",
            "115/115 [==============================] - 6s 53ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 444/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3812 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 445/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3902 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 446/500\n",
            "115/115 [==============================] - 4s 37ms/step - loss: 0.6931 - accuracy: 0.3880 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 447/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 448/500\n",
            "115/115 [==============================] - 3s 30ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 449/500\n",
            "115/115 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 450/500\n",
            "115/115 [==============================] - 4s 39ms/step - loss: 0.6931 - accuracy: 0.3913 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 451/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 452/500\n",
            "115/115 [==============================] - 4s 36ms/step - loss: 0.6931 - accuracy: 0.3897 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 453/500\n",
            "115/115 [==============================] - 4s 38ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 454/500\n",
            "115/115 [==============================] - 4s 37ms/step - loss: 0.6931 - accuracy: 0.3886 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 455/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 456/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 457/500\n",
            "115/115 [==============================] - 4s 38ms/step - loss: 0.6931 - accuracy: 0.3872 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 458/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 459/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 460/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 461/500\n",
            "115/115 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 462/500\n",
            "115/115 [==============================] - 4s 32ms/step - loss: 0.6931 - accuracy: 0.3840 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 463/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 464/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3834 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 465/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 466/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.3859 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 467/500\n",
            "115/115 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.3810 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 468/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3802 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 469/500\n",
            "115/115 [==============================] - 5s 39ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 470/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3872 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 471/500\n",
            "115/115 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.3872 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 472/500\n",
            "115/115 [==============================] - 4s 32ms/step - loss: 0.6931 - accuracy: 0.3837 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 473/500\n",
            "115/115 [==============================] - 4s 38ms/step - loss: 0.6931 - accuracy: 0.3845 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 474/500\n",
            "115/115 [==============================] - 4s 30ms/step - loss: 0.6931 - accuracy: 0.3842 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 475/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3924 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 476/500\n",
            "115/115 [==============================] - 4s 38ms/step - loss: 0.6931 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 477/500\n",
            "115/115 [==============================] - 4s 32ms/step - loss: 0.6931 - accuracy: 0.3853 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 478/500\n",
            "115/115 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.3834 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 479/500\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 0.6931 - accuracy: 0.3848 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 480/500\n",
            "115/115 [==============================] - 4s 35ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 481/500\n",
            "115/115 [==============================] - 4s 37ms/step - loss: 0.6931 - accuracy: 0.3856 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 482/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6931 - accuracy: 0.3837 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 483/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3823 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 484/500\n",
            "115/115 [==============================] - 3s 24ms/step - loss: 0.6931 - accuracy: 0.3880 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 485/500\n",
            "115/115 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 486/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3853 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 487/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3870 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 488/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3867 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 489/500\n",
            "115/115 [==============================] - 5s 40ms/step - loss: 0.6931 - accuracy: 0.3837 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 490/500\n",
            "115/115 [==============================] - 4s 31ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 491/500\n",
            "115/115 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.3889 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 492/500\n",
            "115/115 [==============================] - 3s 28ms/step - loss: 0.6931 - accuracy: 0.3823 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 493/500\n",
            "115/115 [==============================] - 5s 40ms/step - loss: 0.6931 - accuracy: 0.3861 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 494/500\n",
            "115/115 [==============================] - 4s 30ms/step - loss: 0.6931 - accuracy: 0.3834 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 495/500\n",
            "115/115 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.3891 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 496/500\n",
            "115/115 [==============================] - 4s 38ms/step - loss: 0.6931 - accuracy: 0.3815 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 497/500\n",
            "115/115 [==============================] - 3s 25ms/step - loss: 0.6931 - accuracy: 0.3851 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 498/500\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6931 - accuracy: 0.3875 - val_loss: 0.6931 - val_accuracy: 0.3326\n",
            "Epoch 499/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3886 - val_loss: 0.6931 - val_accuracy: 0.3348\n",
            "Epoch 500/500\n",
            "115/115 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.3826 - val_loss: 0.6931 - val_accuracy: 0.3348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print validation accuracy and plot accuracy and loss\n",
        "evaluate_model(history, data_test, label_test, model1)\n",
        "y_pred = model1.predict(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "id": "zjCDG9b9RtkX",
        "outputId": "5a07cbcd-978c-4395-deea-29dec37898d9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 36.09%\n",
            "<keras.callbacks.History object at 0x7f8a39290fd0>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 9ms/step\n",
            "15/15 [==============================] - 0s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Bidirectional LSTM model"
      ],
      "metadata": {
        "id": "x-UU-n1EVniK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def network_LSTM(X_train, y_train):\n",
        "  im_shape = (X_train.shape[1], 1)\n",
        "  inputs_lstm = Input(shape=(im_shape), name='inputs_lstm')\n",
        "\n",
        "  dense = Dense(units=32, activation='relu', name='dense')(inputs_lstm)\n",
        "  lstm = layers.Bidirectional(LSTM(units=128, name='lstm'))(dense)\n",
        "  dropout = Dropout(0.3)(lstm)\n",
        "  batch_normalization = BatchNormalization(name='batch_normalization')(dropout)\n",
        "\n",
        "  dense_1 = Dense(units=64, activation='relu', name='dense_1')(batch_normalization)\n",
        "  dropout_2 = Dropout(0.3, name='dropout_2')(dense_1)\n",
        "  batch_normalization_1 = BatchNormalization(name='batch_normalization_1')(dropout_2)\n",
        "  main_output = Dense(units=2, activation='softmax')(batch_normalization_1)\n",
        "\n",
        "  model = Model(inputs=inputs_lstm, outputs=main_output)\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "Qs9yBJE-SIuC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = network_LSTM(data_train, label_train)\n",
        "print(model2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOW4SJHPXftu",
        "outputId": "373845e3-24e5-473f-a338-c27cd2176d66"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs_lstm (InputLayer)    [(None, 178, 1)]          0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 178, 32)           64        \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 256)              164864    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 182,786\n",
            "Trainable params: 182,146\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train BiLSTM on epileptic vs healthy data\n",
        "save_path = 'checkpoint_2'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=save_path,\n",
        "    save_weight_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "history2 = model2.fit(data_train, label_train, epochs=100, batch_size=32, validation_data=(data_val, label_val), callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0Df52-BXnqg",
        "outputId": "d3ed3c8b-6dd0-459b-c72c-ca7e097d829f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.8997"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r115/115 [==============================] - 99s 815ms/step - loss: 0.2617 - accuracy: 0.8997 - val_loss: 0.1593 - val_accuracy: 0.9391\n",
            "Epoch 2/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.9394"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r115/115 [==============================] - 79s 689ms/step - loss: 0.1680 - accuracy: 0.9394 - val_loss: 0.1172 - val_accuracy: 0.9609\n",
            "Epoch 3/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.9454"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r115/115 [==============================] - 71s 622ms/step - loss: 0.1538 - accuracy: 0.9454 - val_loss: 0.0721 - val_accuracy: 0.9717\n",
            "Epoch 4/100\n",
            "115/115 [==============================] - 53s 460ms/step - loss: 0.1344 - accuracy: 0.9538 - val_loss: 0.0678 - val_accuracy: 0.9717\n",
            "Epoch 5/100\n",
            "115/115 [==============================] - 53s 459ms/step - loss: 0.1244 - accuracy: 0.9549 - val_loss: 0.0816 - val_accuracy: 0.9696\n",
            "Epoch 6/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9595"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r115/115 [==============================] - 69s 601ms/step - loss: 0.1149 - accuracy: 0.9595 - val_loss: 0.0767 - val_accuracy: 0.9761\n",
            "Epoch 7/100\n",
            "115/115 [==============================] - 52s 457ms/step - loss: 0.1119 - accuracy: 0.9620 - val_loss: 0.0797 - val_accuracy: 0.9761\n",
            "Epoch 8/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9595"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r115/115 [==============================] - 69s 600ms/step - loss: 0.1097 - accuracy: 0.9595 - val_loss: 0.0483 - val_accuracy: 0.9826\n",
            "Epoch 9/100\n",
            "115/115 [==============================] - 53s 458ms/step - loss: 0.1082 - accuracy: 0.9658 - val_loss: 0.0589 - val_accuracy: 0.9761\n",
            "Epoch 10/100\n",
            "115/115 [==============================] - 52s 451ms/step - loss: 0.0991 - accuracy: 0.9658 - val_loss: 0.0676 - val_accuracy: 0.9783\n",
            "Epoch 11/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9647"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r115/115 [==============================] - 68s 592ms/step - loss: 0.0975 - accuracy: 0.9647 - val_loss: 0.0581 - val_accuracy: 0.9891\n",
            "Epoch 12/100\n",
            "115/115 [==============================] - 52s 454ms/step - loss: 0.1046 - accuracy: 0.9647 - val_loss: 0.0667 - val_accuracy: 0.9761\n",
            "Epoch 13/100\n",
            "115/115 [==============================] - 53s 464ms/step - loss: 0.1064 - accuracy: 0.9644 - val_loss: 0.0708 - val_accuracy: 0.9804\n",
            "Epoch 14/100\n",
            "115/115 [==============================] - 53s 465ms/step - loss: 0.1088 - accuracy: 0.9649 - val_loss: 0.0654 - val_accuracy: 0.9804\n",
            "Epoch 15/100\n",
            "115/115 [==============================] - 53s 459ms/step - loss: 0.0915 - accuracy: 0.9685 - val_loss: 0.0634 - val_accuracy: 0.9804\n",
            "Epoch 16/100\n",
            "115/115 [==============================] - 52s 455ms/step - loss: 0.0820 - accuracy: 0.9731 - val_loss: 0.0565 - val_accuracy: 0.9826\n",
            "Epoch 17/100\n",
            "115/115 [==============================] - 53s 462ms/step - loss: 0.0895 - accuracy: 0.9720 - val_loss: 0.0783 - val_accuracy: 0.9739\n",
            "Epoch 18/100\n",
            "115/115 [==============================] - 53s 461ms/step - loss: 0.1225 - accuracy: 0.9552 - val_loss: 0.0424 - val_accuracy: 0.9870\n",
            "Epoch 19/100\n",
            "115/115 [==============================] - 52s 457ms/step - loss: 0.0848 - accuracy: 0.9723 - val_loss: 0.0778 - val_accuracy: 0.9761\n",
            "Epoch 20/100\n",
            "115/115 [==============================] - 53s 459ms/step - loss: 0.0884 - accuracy: 0.9677 - val_loss: 0.0482 - val_accuracy: 0.9826\n",
            "Epoch 21/100\n",
            "115/115 [==============================] - 53s 458ms/step - loss: 0.0605 - accuracy: 0.9769 - val_loss: 0.0527 - val_accuracy: 0.9804\n",
            "Epoch 22/100\n",
            "115/115 [==============================] - 52s 454ms/step - loss: 0.0847 - accuracy: 0.9736 - val_loss: 0.1230 - val_accuracy: 0.9674\n",
            "Epoch 23/100\n",
            "115/115 [==============================] - 52s 452ms/step - loss: 0.0671 - accuracy: 0.9761 - val_loss: 0.1593 - val_accuracy: 0.9609\n",
            "Epoch 24/100\n",
            "115/115 [==============================] - 52s 456ms/step - loss: 0.0745 - accuracy: 0.9734 - val_loss: 0.0454 - val_accuracy: 0.9848\n",
            "Epoch 25/100\n",
            "115/115 [==============================] - 52s 456ms/step - loss: 0.0721 - accuracy: 0.9799 - val_loss: 0.0666 - val_accuracy: 0.9826\n",
            "Epoch 26/100\n",
            "115/115 [==============================] - 52s 452ms/step - loss: 0.0602 - accuracy: 0.9799 - val_loss: 0.0488 - val_accuracy: 0.9848\n",
            "Epoch 27/100\n",
            "115/115 [==============================] - 52s 452ms/step - loss: 0.0847 - accuracy: 0.9750 - val_loss: 0.1196 - val_accuracy: 0.9674\n",
            "Epoch 28/100\n",
            "115/115 [==============================] - 52s 451ms/step - loss: 0.0731 - accuracy: 0.9764 - val_loss: 0.1770 - val_accuracy: 0.9435\n",
            "Epoch 29/100\n",
            "115/115 [==============================] - 53s 464ms/step - loss: 0.0808 - accuracy: 0.9745 - val_loss: 0.0587 - val_accuracy: 0.9783\n",
            "Epoch 30/100\n",
            "115/115 [==============================] - 52s 456ms/step - loss: 0.0777 - accuracy: 0.9715 - val_loss: 0.0841 - val_accuracy: 0.9739\n",
            "Epoch 31/100\n",
            "115/115 [==============================] - 53s 464ms/step - loss: 0.0678 - accuracy: 0.9774 - val_loss: 0.0558 - val_accuracy: 0.9826\n",
            "Epoch 32/100\n",
            "115/115 [==============================] - 53s 459ms/step - loss: 0.0616 - accuracy: 0.9793 - val_loss: 0.0690 - val_accuracy: 0.9761\n",
            "Epoch 33/100\n",
            "115/115 [==============================] - 53s 458ms/step - loss: 0.0645 - accuracy: 0.9766 - val_loss: 0.0804 - val_accuracy: 0.9848\n",
            "Epoch 34/100\n",
            "115/115 [==============================] - 52s 456ms/step - loss: 0.0659 - accuracy: 0.9799 - val_loss: 0.0532 - val_accuracy: 0.9870\n",
            "Epoch 35/100\n",
            " 52/115 [============>.................] - ETA: 28s - loss: 0.0540 - accuracy: 0.9832"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(history2, data_test, label_test, model2)"
      ],
      "metadata": {
        "id": "KakFWCK4YUNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.load_weights(save_path)\n",
        "evaluate_model(history2, data_test, label_test, model2)"
      ],
      "metadata": {
        "id": "AevEd59QYwIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wsbHP-NgZAca"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}